{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d977dd9-de5a-4f7b-b938-307333aeee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/local/openjdk-8\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/user_data/spark-3.3.0-bin-hadoop2\"\n",
    "\n",
    "import findspark\n",
    "findspark.init('spark-3.3.0-bin-hadoop2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00f41645-7cd9-42df-b97a-8e33155684c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/15 02:26:03 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"sparksubmit_test_app\")\n",
    "    .config(\"spark.sql.warehouse.dir\", \"hdfs:///user/hive/warehouse\")\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8810af9-0f2b-4813-a2f6-98e9233a50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.text(\"hdfs://spark-master:9000/datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace71e35-e02f-4036-bfcc-4c3fab66081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb01bb0f-0cd7-4b18-937c-3d76eb3262c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n",
      "|_c0|_c1|_c2|_c3|        _c4|\n",
      "+---+---+---+---+-----------+\n",
      "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
      "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
      "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
      "|5.0|3.6|1.4|0.2|Iris-setosa|\n",
      "|5.4|3.9|1.7|0.4|Iris-setosa|\n",
      "|4.6|3.4|1.4|0.3|Iris-setosa|\n",
      "|5.0|3.4|1.5|0.2|Iris-setosa|\n",
      "|4.4|2.9|1.4|0.2|Iris-setosa|\n",
      "|4.9|3.1|1.5|0.1|Iris-setosa|\n",
      "|5.4|3.7|1.5|0.2|Iris-setosa|\n",
      "|4.8|3.4|1.6|0.2|Iris-setosa|\n",
      "|4.8|3.0|1.4|0.1|Iris-setosa|\n",
      "|4.3|3.0|1.1|0.1|Iris-setosa|\n",
      "|5.8|4.0|1.2|0.2|Iris-setosa|\n",
      "|5.7|4.4|1.5|0.4|Iris-setosa|\n",
      "|5.4|3.9|1.3|0.4|Iris-setosa|\n",
      "|5.1|3.5|1.4|0.3|Iris-setosa|\n",
      "|5.7|3.8|1.7|0.3|Iris-setosa|\n",
      "|5.1|3.8|1.5|0.3|Iris-setosa|\n",
      "+---+---+---+---+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Número de linhas no DataFrame: 150\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "df = spark.read.csv(\"hdfs://spark-master:9000/datasets/iris/iris.data\", header=False, inferSchema=True)\n",
    "\n",
    "df.show()\n",
    "\n",
    "num_linhas = df.count()\n",
    "print(f\"Número de linhas no DataFrame: {num_linhas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6ccf842-666e-4f07-bd72-15ed7bf40a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformado = df.select(\"_c0\", \"_c1\").filter(df[\"_c4\"] == 'Iris-setosa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "170c54cf-fdba-4a44-adb3-1a99662a871a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|_c0|_c1|\n",
      "+---+---+\n",
      "|5.1|3.5|\n",
      "|4.9|3.0|\n",
      "|4.7|3.2|\n",
      "|4.6|3.1|\n",
      "|5.0|3.6|\n",
      "|5.4|3.9|\n",
      "|4.6|3.4|\n",
      "|5.0|3.4|\n",
      "|4.4|2.9|\n",
      "|4.9|3.1|\n",
      "|5.4|3.7|\n",
      "|4.8|3.4|\n",
      "|4.8|3.0|\n",
      "|4.3|3.0|\n",
      "|5.8|4.0|\n",
      "|5.7|4.4|\n",
      "|5.4|3.9|\n",
      "|5.1|3.5|\n",
      "|5.7|3.8|\n",
      "|5.1|3.8|\n",
      "+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "232ff9e4-adbf-4311-8fd5-94c460e6a3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|_c0|          avg(_c1)|\n",
      "+---+------------------+\n",
      "|5.4|3.5500000000000003|\n",
      "|7.0|               3.2|\n",
      "|6.1|              2.85|\n",
      "|7.7|              3.05|\n",
      "|6.6|              2.95|\n",
      "|4.5|               2.3|\n",
      "|5.7|               3.1|\n",
      "|6.7|3.0500000000000003|\n",
      "|7.4|               2.8|\n",
      "|6.5|               3.0|\n",
      "|4.9|2.8666666666666667|\n",
      "|6.2|2.8249999999999997|\n",
      "|5.1| 3.477777777777778|\n",
      "|7.3|               2.9|\n",
      "|4.3|               3.0|\n",
      "|7.9|               3.8|\n",
      "|4.7|               3.2|\n",
      "|5.3|               3.7|\n",
      "|7.2| 3.266666666666667|\n",
      "|7.6|               3.0|\n",
      "+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Registrar DataFrame como tabela temporária\n",
    "df.createOrReplaceTempView(\"tabela_temporaria\")\n",
    "\n",
    "# Executar consulta SQL no DataFrame\n",
    "resultado_sql = spark.sql(\"SELECT _c0, AVG(_c1) FROM tabela_temporaria GROUP BY _c0\")\n",
    "resultado_sql.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
